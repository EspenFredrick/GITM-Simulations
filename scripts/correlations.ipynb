{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T20:01:01.575092Z",
     "start_time": "2024-12-11T20:01:01.216146Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from doCorrelate import *\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "omniFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('../Ordinary Solar Wind/omni', x)), os.listdir('../Ordinary Solar Wind/omni')))\n",
    "artemisFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('../Ordinary Solar Wind/artemis', x)), os.listdir('../Ordinary Solar Wind/artemis')))\n",
    "\n",
    "file_pairs = [(os.path.join('../Ordinary Solar Wind/artemis', artemis_file), os.path.join('../Ordinary Solar Wind/omni', omni_file)) for artemis_file, omni_file in zip(artemisFileList, omniFileList) if not artemis_file.startswith('.') and not 'copy' in artemis_file]\n",
    "\n",
    "for f in file_pairs:\n",
    "    artemis_file = pd.read_csv(f[0], delimiter=',', header=0)\n",
    "    omni_file = pd.read_csv(f[1], delimiter=',', header=0)\n",
    "    artemis_file = artemis_file.rename(columns={'XPOS': 'Xpos'})\n",
    "    # Reformat the time column to DateTime objects../Ordinary Solar Wind/omni'\n",
    "    artemis_file['Time'] = pd.to_datetime(artemis_file['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    omni_file['Time'] = pd.to_datetime(omni_file['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    artemis_file['V'] = np.sqrt(artemis_file['VX']**2 + artemis_file['VY']**2 + artemis_file['VZ']**2)\n",
    "    omni_file['V'] = np.sqrt(omni_file['VX']**2 + omni_file['VY']**2 + omni_file['VZ']**2)\n",
    "\n",
    "    print(artemis_file['Time'][0], omni_file['Time'][0])\n",
    "    correlate((artemis_file, omni_file), 'outputs', 'V')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "from os import listdir\n",
    "import csv\n",
    "\n",
    "def process_file(file):\n",
    "    #load the text file as list using csv module\n",
    "    #run a bunch of operations\n",
    "    #regex the int from the filename. for ex file1.txt returns 1, and file42.txt returns 42\n",
    "    #write out a corresponsding csv file in dirB. For example input file file99.txt is written as out99.csv\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mypath = \"some/path/\"\n",
    "\n",
    "    inputDir = mypath + 'dirA/'\n",
    "    outputDir = mypath + 'dirB/'\n",
    "\n",
    "    p = Pool(12)\n",
    "    p.map(process_file, listdir(inputDir))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from doCorrelate import correlate  # Ensure this is accessible\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Prepare file pairs\n",
    "omniFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('../Ordinary Solar Wind/omni', x)), os.listdir('../Ordinary Solar Wind/omni')))\n",
    "artemisFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('../Ordinary Solar Wind/artemis', x)), os.listdir('../Ordinary Solar Wind/artemis')))\n",
    "\n",
    "file_pairs = [\n",
    "    (os.path.join('../Ordinary Solar Wind/artemis', artemis_file),\n",
    "     os.path.join('../Ordinary Solar Wind/omni', omni_file))\n",
    "    for artemis_file, omni_file in zip(artemisFileList, omniFileList)\n",
    "    if not artemis_file.startswith('.') and 'copy' not in artemis_file\n",
    "]\n",
    "\n",
    "# Define the processing function\n",
    "def process_files(file_pair, mode, base_output_dir):\n",
    "    artemis_file = pd.read_csv(file_pair[0], delimiter=',', header=0)\n",
    "    omni_file = pd.read_csv(file_pair[1], delimiter=',', header=0)\n",
    "    artemis_file = artemis_file.rename(columns={'XPOS': 'Xpos'})\n",
    "    artemis_file['Time'] = pd.to_datetime(artemis_file['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    omni_file['Time'] = pd.to_datetime(omni_file['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if mode == \"Bx\":\n",
    "        output_dir = os.path.join(base_output_dir, 'Bx')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Processing Bx: {artemis_file['Time'][0]} vs {omni_file['Time'][0]}\")\n",
    "        correlate((artemis_file, omni_file), output_dir, 'BX_GSM')\n",
    "    elif mode == \"V\":\n",
    "        output_dir = os.path.join(base_output_dir, 'V')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        artemis_file['V'] = np.sqrt(artemis_file['VX']**2 + artemis_file['VY']**2 + artemis_file['VZ']**2)\n",
    "        omni_file['V'] = np.sqrt(omni_file['VX']**2 + omni_file['VY']**2 + omni_file['VZ']**2)\n",
    "        print(f\"Processing V (quadrature): {artemis_file['Time'][0]} vs {omni_file['Time'][0]}\")\n",
    "        correlate((artemis_file, omni_file), output_dir, 'V')\n",
    "\n",
    "# Parallelize the tasks\n",
    "output_dir_base = '../Ordinary Solar Wind/correlations'\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    tasks = []\n",
    "    for i, file_pair in enumerate(file_pairs[1:]):  # Skip the first pair if needed\n",
    "        if i % 2 == 0:  # Task 1: Correlate Bx\n",
    "            tasks.append(executor.submit(process_files, file_pair, \"Bx\", output_dir_base))\n",
    "        else:  # Task 2: Correlate velocity magnitude V\n",
    "            tasks.append(executor.submit(process_files, file_pair, \"V\", output_dir_base))\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    for task in tasks:\n",
    "        task.result()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from parallel_tasks_temp import process_files  # Import the function from the new module\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Prepare file pairs\n",
    "omniFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('../Ordinary Solar Wind/omni', x)), os.listdir('../Ordinary Solar Wind/omni')))\n",
    "artemisFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('../Ordinary Solar Wind/artemis', x)), os.listdir('../Ordinary Solar Wind/artemis')))\n",
    "\n",
    "file_pairs = [\n",
    "    (os.path.join('../Ordinary Solar Wind/artemis', artemis_file),\n",
    "     os.path.join('../Ordinary Solar Wind/omni', omni_file))\n",
    "    for artemis_file, omni_file in zip(artemisFileList, omniFileList)\n",
    "    if not artemis_file.startswith('.') and 'copy' not in artemis_file\n",
    "]\n",
    "\n",
    "# Parallelize the tasks\n",
    "output_dir_base = '../Ordinary Solar Wind/correlations'\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    tasks = []\n",
    "    for i, file_pair in enumerate(file_pairs[1:]):  # Skip the first pair if needed\n",
    "        if i % 2 == 0:  # Task 1: Correlate Bx\n",
    "            tasks.append(executor.submit(process_files, file_pair, \"Bx\", output_dir_base))\n",
    "        else:  # Task 2: Correlate velocity magnitude V\n",
    "            tasks.append(executor.submit(process_files, file_pair, \"V\", output_dir_base))\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    for task in tasks:\n",
    "        task.result()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from doCorrelate import *\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "omniFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('../Ordinary Solar Wind/omni'', x)), os.listdir('outputs/omni')))\n",
    "artemisFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('outputs/artemis', x)), os.listdir('outputs/artemis')))\n",
    "\n",
    "file_pairs = [(os.path.join('outputs/artemis', artemis_file), os.path.join('outputs/omni', omni_file)) for artemis_file, omni_file in zip(artemisFileList, omniFileList) if not artemis_file.startswith('.') and not 'copy' in artemis_file]\n",
    "\n",
    "for f in file_pairs:\n",
    "    artemis_file = pd.read_csv(f[0], delimiter=',', header=0)\n",
    "    omni_file = pd.read_csv(f[1], delimiter=',', header=0)\n",
    "    artemis_file = artemis_file.rename(columns={'XPOS': 'Xpos'})\n",
    "    # Reformat the time column to DateTime objects\n",
    "    artemis_file['Time'] = pd.to_datetime(artemis_file['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    omni_file['Time'] = pd.to_datetime(omni_file['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    print(artemis_file['Time'][0], omni_file['Time'][0])\n",
    "    corr, shift = correlate_whole_day(artemis_file, omni_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "directory = '../Ordinary Solar Wind/correlations/Bz/metrics'\n",
    "frame = []\n",
    "\n",
    "# Sort filenames in date order\n",
    "filenames = sorted(f for f in os.listdir(directory) if not f.startswith('.'))\n",
    "\n",
    "# Append files in sorted order\n",
    "for filename in filenames:\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    file = pd.read_csv(file_path, delimiter=',', header=0, index_col=0)\n",
    "    frame.append(file)\n",
    "\n",
    "# Concatenate into a single DataFrame\n",
    "df = pd.concat(frame, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_dir = '../Ordinary Solar Wind/correlations/Bz/merged'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df.to_csv(os.path.join(output_dir, 'output.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frame = []\n",
    "directory = '../Ordinary Solar Wind/correlations/By/metrics'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.startswith('.'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        file = pd.read_csv(file_path, delimiter=',', header=0, index_col=0)\n",
    "        frame.append(file)\n",
    "df = pd.concat(frame, axis=0, ignore_index=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "if os.path.exists('../Ordinary Solar Wind/correlations/By/merged'):\n",
    "    df.to_csv('../Ordinary Solar Wind/correlations/By/merged/output.csv')\n",
    "else:\n",
    "    os.makedirs('../Ordinary Solar Wind/correlations/By/merged')\n",
    "    df.to_csv('../Ordinary Solar Wind/correlations/By/merged/output.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = pd.read_csv('outputs/new-correlations-3/merged/output.csv', delimiter=',', header=0, index_col=0)\n",
    "\n",
    "store = pd.DataFrame(columns=['Start', 'Stop', 'Pearson'])\n",
    "\n",
    "filtered_df= file[(file['Pearson'] >= 0.65) & (file['Pearson'] <= 0.66)]\n",
    "filtered_df.to_csv('5okdays/DaysAround065.csv')\n",
    "\n",
    "\n",
    "filtered_df['Start'] = pd.to_datetime(filtered_df['Start']).dt.date\n",
    "unique_date = filtered_df.drop_duplicates(subset=['Start'], keep='first')\n",
    "\n",
    "#unique_date.to_csv('DatesAround85.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "omniFileList = sorted(filter(lambda x: os.path.isfile(os.path.join('outputs/omni', x)), os.listdir('outputs/omni')))\n",
    "\n",
    "minutes = []\n",
    "for f in omniFileList:\n",
    "    if not f.startswith('.'):\n",
    "        omni_file = pd.read_csv(f'outputs/omni/{f}', delimiter=',', header=0)\n",
    "        minutes.append(len(omni_file['Time']))\n",
    "\n",
    "print(sum(minutes)-60)\n",
    "print(sum(minutes)/60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
